_BASE_: ../../ovis_noise/CT_MinVIS_R50.yaml
MODEL:
  META_ARCHITECTURE: "ViHub_online"
  MASK_FORMER:
    TRANSFORMER_DECODER_NAME: "VideoMultiScaleMaskedTransformerDecoder_ctdvis"
    TEST:
      MAX_NUM: 20
  VIDEO_HEAD:
    NUM_NEW_INS: 100
    TRAINING_SELECT_THRESHOLD: 0.1
    INFERENCE_SELECT_THRESHOLD: 0.1
    NOISE_FRAME_NUM: 5
    NUM_REID_HEAD_LAYERS: 0
    NUM_WARMING_LAYERS: 3
    USING_THR: True

SOLVER:
  IMS_PER_BATCH: 8
  STEPS: (48000,)
  MAX_ITER: 60000
  CHECKPOINT_PERIOD: 5000

INPUT:
  SAMPLING_FRAME_NUM: 5
  SAMPLING_FRAME_RANGE: 2
  SAMPLING_FRAME_SHUFFLE: False
  USING_FRAME_NUM: [3, 4, 5]
  STEPS: [10000, 20000]
#  CROP:
#    ENABLED: False

#DATASETS:
#  DATASET_RATIO: [1.0, ]
#  DATASET_NEED_MAP: [False, ]
#  DATASET_TYPE: ['video_instance', ]
#  DATASET_TYPE_TEST: ['video_instance', ]
#  # The categories of all datasets will be mapped to the categories of the last dataset
#  TRAIN: ("ovis_train", )
#  TEST: ("ovis_val",)

TEST:
  EVAL_PERIOD: 0

OUTPUT_DIR: './output_ViHub_Online_R50_v5-5_f5'